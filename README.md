# G1 Sentiment Analyzer ğŸš€

AplicaÃ§Ã£o **Full Stack** para coleta, anÃ¡lise e visualizaÃ§Ã£o de sentimentos em notÃ­cias do portal **G1**, utilizando **Web Scraping**, **InteligÃªncia Artificial (Google Gemini)** e um **dashboard interativo**.

O projeto automatiza todo o fluxo: desde a extraÃ§Ã£o das manchetes atÃ© a exibiÃ§Ã£o grÃ¡fica dos sentimentos classificados.

---

## ğŸ“Œ VisÃ£o Geral

O G1 Sentiment Analyzer realiza:
- Coleta automÃ¡tica de notÃ­cias recentes do G1
- AnÃ¡lise de sentimento com IA
- Armazenamento estruturado dos dados
- VisualizaÃ§Ã£o interativa em tempo real

---

## ğŸ§  Arquitetura do Projeto

- **Crawler:** ResponsÃ¡vel por coletar as manchetes do G1
- **Backend:** Processa, analisa e persiste os dados
- **IA:** Classifica o sentimento das notÃ­cias
- **Banco de Dados:** Armazena as informaÃ§Ãµes analisadas
- **Frontend:** Exibe grÃ¡ficos e indicadores visuais

---

## ğŸ›  Tecnologias Utilizadas

### Backend
- Python
- Django
- Django REST Framework

### Frontend
- React
- Tailwind CSS
- Recharts

### Scraping
- Scrapy

### InteligÃªncia Artificial
- Google Gemini API

### Banco de Dados
- PostgreSQL
- Docker e Docker Compose

---

## âš™ï¸ PrÃ©-requisitos

Antes de iniciar, certifique-se de ter instalado:
- Python
- Node.js 
- Docker
- Docker Compose

---

## ğŸ” VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto (e adicione-o ao `.gitignore`):

GEMINI_API_KEY=sua_chave_aqui  

---

## â–¶ï¸ Passo a Passo para ExecuÃ§Ã£o

Para rodar o projeto completo, utilize **4 terminais** simultaneamente.

---

### ğŸŸ¢ Terminal 1 â€” Banco de Dados (Docker)

Subir o container do PostgreSQL:

docker-compose up -d

---

### ğŸŸ¡ Terminal 2 â€” Backend (Django)

Criar e ativar o ambiente virtual:

python -m venv venv  
venv\Scripts\activate  

Instalar dependÃªncias e executar o servidor:

pip install -r requirements.txt  
python manage.py migrate  
python manage.py runserver  

O backend ficarÃ¡ disponÃ­vel em:  
http://localhost:8000

---

### ğŸ”µ Terminal 3 â€” Frontend (React)

Acessar o diretÃ³rio do frontend e iniciar a aplicaÃ§Ã£o:

cd frontend  
npm install  
npm run dev  

O frontend ficarÃ¡ disponÃ­vel em:  
http://localhost:5173

---

### ğŸŸ£ Terminal 4 â€” Scraping de NotÃ­cias

Executar o crawler para coletar as notÃ­cias:

scrapy crawl g1

---

## ğŸ”„ Fluxo de Funcionamento

1. **Scraping:** O Scrapy coleta manchetes recentes do portal G1.
2. **Envio ao Backend:** As notÃ­cias sÃ£o enviadas para a API Django.
3. **AnÃ¡lise de Sentimento:** O texto Ã© processado pela API do Google Gemini.
4. **ClassificaÃ§Ã£o:** A IA classifica o sentimento como Positivo, Negativo ou Neutro.
5. **PersistÃªncia:** Os dados analisados sÃ£o salvos no PostgreSQL.
6. **VisualizaÃ§Ã£o:** O frontend consome a API e exibe grÃ¡ficos interativos com Recharts.

---

## ğŸ“Š Dashboard

O dashboard apresenta:
- DistribuiÃ§Ã£o dos sentimentos
- GrÃ¡ficos interativos
- AtualizaÃ§Ã£o dinÃ¢mica conforme novas notÃ­cias sÃ£o analisadas

---

## ğŸš§ Melhorias Futuras

- AnÃ¡lise por categorias de notÃ­cia
- HistÃ³rico temporal de sentimentos
- AutenticaÃ§Ã£o de usuÃ¡rios
- Deploy em nuvem
- Cache de resultados

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© de uso educacional e experimental.

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido para estudo de **Web Scraping**, **IA aplicada** e **Arquitetura Full Stack**.
